diff -u qtwebkit-opensource-src-5.2.1/Source/WebCore/platform/graphics/gstreamer/MediaPlayerPrivateGStreamerBase.cpp qt5webkit-5.2.1/Source/WebCore/platform/graphics/gstreamer/MediaPlayerPrivateGStreamerBase.cpp
--- qtwebkit-opensource-src-5.2.1/Source/WebCore/platform/graphics/gstreamer/MediaPlayerPrivateGStreamerBase.cpp	2014-02-01 21:37:48.000000000 +0100
+++ qt5webkit-5.2.1/Source/WebCore/platform/graphics/gstreamer/MediaPlayerPrivateGStreamerBase.cpp	2014-02-24 10:57:35.000000000 +0100
@@ -51,10 +51,37 @@
 #include <gst/interfaces/streamvolume.h>
 #endif
 
-#if GST_CHECK_VERSION(1, 1, 0) && USE(ACCELERATED_COMPOSITING) && USE(TEXTURE_MAPPER_GL)
+#if USE(ACCELERATED_COMPOSITING) && USE(TEXTURE_MAPPER_GL)
 #include "TextureMapperGL.h"
 #endif
 
+#if USE(ACCELERATED_COMPOSITING) && USE(TEXTURE_MAPPER_GL) && PLATFORM(QT)
+#define GL_GLEXT_PROTOTYPES
+#include "OpenGLShims.h"
+#endif
+
+
+#if USE(OPENGL_ES_2)
+#include <GLES2/gl2.h>
+#include <GLES2/gl2ext.h>
+#if GST_CHECK_VERSION(1, 1, 2)
+#include <gst/egl/egl.h>
+#endif
+#endif
+
+#define EGL_EGLEXT_PROTOTYPES
+#include <EGL/egl.h>
+#ifndef GST_API_VERSION_1
+#include <gst/egl/egl.h>
+#endif
+
+struct _EGLDetails {
+    EGLDisplay display;
+    EGLContext context;
+    EGLSurface draw;
+    EGLSurface read;
+};
+
 GST_DEBUG_CATEGORY(webkit_media_player_debug);
 #define GST_CAT_DEFAULT webkit_media_player_debug
 
@@ -99,6 +126,37 @@
     return FALSE;
 }
 
+#ifndef GST_API_VERSION_1
+static void mediaPlayerPrivateVideoPrerollCallback(GstElement* fakesink, GstBuffer* buffer, GstPad* pad, MediaPlayerPrivateGStreamerBase* player)
+{
+    player->updateEGLMemory(buffer);
+}
+
+static void mediaPlayerPrivateVideoBufferCallback(GstElement* fakesink, GstBuffer* buffer, GstPad* pad, MediaPlayerPrivateGStreamerBase* player)
+{
+    player->updateEGLMemory(buffer);
+}
+
+static gboolean mediaPlayerPrivateVideoEventCallback(GstPad* pad, GstEvent* event, MediaPlayerPrivateGStreamerBase* player)
+{
+    switch (GST_EVENT_TYPE (event)) {
+        case GST_EVENT_FLUSH_START:
+            player->queueFlushStart();
+            break;
+        case GST_EVENT_FLUSH_STOP:
+            player->queueFlushStop();
+            break;
+        case GST_EVENT_EOS:
+            player->queueObject(GST_MINI_OBJECT_CAST (gst_event_ref (event)), FALSE);
+            break;
+        default:
+            break;
+    }
+
+    return TRUE;
+}
+#endif
+
 static void mediaPlayerPrivateRepaintCallback(WebKitVideoSink*, GstBuffer *buffer, MediaPlayerPrivateGStreamerBase* playerPrivate)
 {
     playerPrivate->triggerRepaint(buffer);
@@ -115,6 +173,13 @@
     , m_repaintHandler(0)
     , m_volumeSignalHandler(0)
     , m_muteSignalHandler(0)
+#ifndef GST_API_VERSION_1
+    , m_queueFlushing(false)
+    , m_queueLastObject(NULL)
+    , m_currentEGLMemory(NULL)
+    , m_lastEGLMemory(NULL)
+    , m_egl_details(NULL)
+#endif
 {
 #if GLIB_CHECK_VERSION(2, 31, 0)
     m_bufferMutex = WTF::fastNew<GMutex>();
@@ -122,11 +187,27 @@
 #else
     m_bufferMutex = g_mutex_new();
 #endif
+
+#ifndef GST_API_VERSION_1
+    m_queue = g_async_queue_new_full((GDestroyNotify) gst_mini_object_unref);
+    m_queueLock = WTF::fastNew<GMutex>();
+    g_mutex_init(m_queueLock);
+    m_queueCond = WTF::fastNew<GCond>();
+    g_cond_init(m_queueCond);
+#endif
 }
 
 MediaPlayerPrivateGStreamerBase::~MediaPlayerPrivateGStreamerBase()
 {
-    g_signal_handler_disconnect(m_webkitVideoSink.get(), m_repaintHandler);
+    if (m_repaintHandler) {
+        g_signal_handler_disconnect(m_webkitVideoSink.get(), m_repaintHandler);
+        m_repaintHandler = 0;
+    }
+
+#ifndef GST_API_VERSION_1
+    g_signal_handlers_disconnect_by_func(m_webkitVideoSink.get(), reinterpret_cast<gpointer>(mediaPlayerPrivateVideoPrerollCallback), this);
+    g_signal_handlers_disconnect_by_func(m_webkitVideoSink.get(), reinterpret_cast<gpointer>(mediaPlayerPrivateVideoBufferCallback), this);
+#endif
 
 #if GLIB_CHECK_VERSION(2, 31, 0)
     g_mutex_clear(m_bufferMutex);
@@ -143,9 +224,11 @@
 
     if (m_muteTimerHandler)
         g_source_remove(m_muteTimerHandler);
+    m_muteTimerHandler = 0;
 
     if (m_volumeTimerHandler)
         g_source_remove(m_volumeTimerHandler);
+    m_volumeTimerHandler = 0;
 
     if (m_volumeSignalHandler) {
         g_signal_handler_disconnect(m_volumeElement.get(), m_volumeSignalHandler);
@@ -157,10 +240,36 @@
         m_muteSignalHandler = 0;
     }
 
+#ifndef GST_API_VERSION_1
+    if (m_egl_details) {
+        delete m_egl_details;
+        m_egl_details = NULL;
+    }
+#endif
+
 #if USE(NATIVE_FULLSCREEN_VIDEO)
     if (m_fullscreenVideoController)
         exitFullscreen();
 #endif
+
+#ifndef GST_API_VERSION_1
+    queueFlushStop();
+
+    if (m_queue) {
+        g_async_queue_unref (m_queue);
+    }
+
+    if (m_queueLock) {
+        g_mutex_clear(m_queueLock);
+        WTF::fastDelete(m_queueLock);
+    }
+
+    if (m_queueCond) {
+        g_cond_clear(m_queueCond);
+        WTF::fastDelete(m_queueCond);
+    }
+    LOG_MEDIA_MESSAGE("Player destroyed");
+#endif
 }
 
 // Returns the size of the video
@@ -320,8 +429,276 @@
     m_muteTimerHandler = g_timeout_add(0, reinterpret_cast<GSourceFunc>(mediaPlayerPrivateMuteChangeTimeoutCallback), this);
 }
 
+#ifndef GST_API_VERSION_1
+static gboolean mediaPlayerPrivateProcessQueueCallback (MediaPlayerPrivateGStreamerBase* player)
+{
+    player->triggerRepaint();
+    return FALSE;
+}
 
-#if USE(ACCELERATED_COMPOSITING) && USE(TEXTURE_MAPPER_GL) && !USE(COORDINATED_GRAPHICS)
+void MediaPlayerPrivateGStreamerBase::updateEGLMemory (GstBuffer * buffer)
+{
+    g_mutex_lock (m_queueLock);
+    if (m_currentEGLMemory) {
+        gst_egl_image_memory_unref (m_currentEGLMemory);
+        m_currentEGLMemory = NULL;
+    }
+    if (GST_BUFFER_FLAG_IS_SET (buffer, GST_BUFFER_FLAG_PREROLL) || m_queueFlushing) {
+        if (m_lastEGLMemory) {
+            gst_egl_image_memory_unref (m_lastEGLMemory);
+            m_lastEGLMemory = NULL;
+        }
+    } else {
+        GstEGLImageMemory *mem = (GstEGLImageMemory *) GST_BUFFER_DATA (buffer);
+        LOG_MEDIA_MESSAGE("Buffer %" GST_TIME_FORMAT " EGL Image: %p", GST_TIME_ARGS(GST_BUFFER_TIMESTAMP (buffer)), gst_egl_image_memory_get_image (mem));
+        m_currentEGLMemory = gst_egl_image_memory_ref (mem);
+        g_timeout_add_full (G_PRIORITY_HIGH, 0, (GSourceFunc) mediaPlayerPrivateProcessQueueCallback,
+            this, NULL);
+    }
+    g_mutex_unlock (m_queueLock);
+}
+
+gboolean MediaPlayerPrivateGStreamerBase::queueObject (GstMiniObject * obj, gboolean synchronous)
+{
+    gboolean res = TRUE;
+    g_mutex_lock (m_queueLock);
+    if (m_queueFlushing) {
+        gst_mini_object_unref (obj);
+        res = FALSE;
+        goto beach;
+    }
+
+    LOG_MEDIA_MESSAGE("queue object: %p", obj);
+    g_async_queue_push (m_queue, obj);
+
+    g_timeout_add_full (G_PRIORITY_HIGH, 0, (GSourceFunc) mediaPlayerPrivateProcessQueueCallback,
+        this, NULL);
+
+    if (synchronous) {
+        /* Waiting for object to be handled */
+        do {
+            g_cond_wait (m_queueCond, m_queueLock);
+        } while (!m_queueFlushing && m_queueLastObject != obj);
+    }
+
+beach:
+    g_mutex_unlock (m_queueLock);
+    LOG_MEDIA_MESSAGE("queue object: done");
+    return res;
+}
+
+void MediaPlayerPrivateGStreamerBase::dequeueObjects ()
+{
+    GstMiniObject *object = NULL;
+
+    g_mutex_lock (m_queueLock);
+    if (m_queueFlushing) {
+        g_cond_broadcast (m_queueCond);
+    } else if ((object = GST_MINI_OBJECT_CAST (g_async_queue_try_pop (m_queue)))) {
+        if (GST_IS_MESSAGE (object)) {
+            GstMessage *message = GST_MESSAGE_CAST (object);
+            if (gst_structure_has_name (message->structure, "need-egl-pool")) {
+                GstElement *element = GST_ELEMENT (GST_MESSAGE_SRC (message));
+                gint size, width, height;
+
+                gst_message_parse_need_egl_pool (message, &size, &width, &height);
+
+                if (g_object_class_find_property (G_OBJECT_GET_CLASS (element), "pool")) {
+                    GstEGLImageMemoryPool *pool = NULL;
+
+                    if ((pool = createEGLPool (size, width, height))) {
+                        g_object_set (element, "pool", pool, NULL);
+                    }
+                }
+            }
+            gst_message_unref (message);
+        } else if (GST_IS_EVENT (object)) {
+            GstEvent *event = GST_EVENT_CAST (object);
+
+            switch (GST_EVENT_TYPE (event)) {
+                case GST_EVENT_EOS:
+                    if (m_lastEGLMemory) {
+                        gst_egl_image_memory_unref (m_lastEGLMemory);
+                        m_lastEGLMemory = NULL;
+                        object = NULL;
+                    }
+                    break;
+                default:
+                    break;
+            }
+            gst_event_unref (event);
+        }
+    }
+
+    if (object) {
+        m_queueLastObject = object;
+        LOG_MEDIA_MESSAGE("dequeued %p", object);
+        g_cond_broadcast (m_queueCond);
+    }
+    g_mutex_unlock (m_queueLock);
+}
+
+void MediaPlayerPrivateGStreamerBase::queueFlushStart()
+{
+    LOG_MEDIA_MESSAGE("Flush Start");
+    GstMiniObject *object = NULL;
+
+    g_mutex_lock (m_queueLock);
+    m_queueFlushing = true;
+    g_cond_broadcast (m_queueCond);
+    g_mutex_unlock (m_queueLock);
+
+    while ((object = GST_MINI_OBJECT_CAST (g_async_queue_try_pop (m_queue)))) {
+        gst_mini_object_unref (object);
+    }
+
+    g_mutex_lock (m_queueLock);
+    if (m_currentEGLMemory)
+        gst_egl_image_memory_unref (m_currentEGLMemory);
+    m_currentEGLMemory = NULL;
+
+    if (m_lastEGLMemory)
+        gst_egl_image_memory_unref (m_lastEGLMemory);
+    m_lastEGLMemory = NULL;
+
+    m_queueLastObject = NULL;
+    g_mutex_unlock (m_queueLock);
+}
+
+void MediaPlayerPrivateGStreamerBase::queueFlushStop()
+{
+    GstMiniObject *object = NULL;
+
+    g_mutex_lock (m_queueLock);
+    if (m_currentEGLMemory)
+        gst_egl_image_memory_unref (m_currentEGLMemory);
+    m_currentEGLMemory = NULL;
+
+    if (m_lastEGLMemory)
+        gst_egl_image_memory_unref (m_lastEGLMemory);
+    m_lastEGLMemory = NULL;
+
+    while ((object = GST_MINI_OBJECT_CAST (g_async_queue_try_pop (m_queue)))) {
+        gst_mini_object_unref (object);
+    }
+    m_queueLastObject = NULL;
+    m_queueFlushing = false;
+    g_mutex_unlock (m_queueLock);
+    LOG_MEDIA_MESSAGE("Flush Stop");
+}
+
+static void destroy_pool_resources (GstEGLImageMemoryPool * pool, gpointer user_data)
+{
+    gint i, size = gst_egl_image_memory_pool_get_size (pool);
+    EGLClientBuffer client_buffer;
+    EGLImageKHR image;
+    EGLint error;
+
+    /* reset error state */
+    while (glGetError() != GL_NO_ERROR);
+
+    GstEGLDisplay * gst_display = gst_egl_image_memory_pool_get_display (pool);
+    EGLDisplay display = gst_egl_display_get (gst_display);
+    gst_egl_display_unref (gst_display);
+
+    for (i = 0; i < size; i++) {
+        if (gst_egl_image_memory_pool_get_resources (pool, i, &client_buffer,
+                &image)) {
+            GLuint tid = (GLuint) client_buffer;
+            error = EGL_SUCCESS;
+
+            if (image != EGL_NO_IMAGE_KHR) {
+                eglDestroyImageKHR (display, image);
+                if ((error = eglGetError ()) != EGL_SUCCESS) {
+                    LOG_MEDIA_MESSAGE("eglDestroyImageKHR failed %x", error);
+                }
+            }
+
+            if (tid) {
+                error = GL_NO_ERROR;
+                glDeleteTextures (1, &tid);
+                if ((error = glGetError ()) != GL_NO_ERROR) {
+                    LOG_MEDIA_MESSAGE("glDeleteTextures failed %x", error);
+                }
+            }
+            LOG_MEDIA_MESSAGE("destroyed texture %x image %p", tid, image);
+        }
+    }
+}
+GstEGLImageMemoryPool* MediaPlayerPrivateGStreamerBase::createEGLPool(gint size, gint width, gint height)
+{
+    GstEGLImageMemoryPool *pool;
+    gint i;
+    EGLint error;
+    GstEGLDisplay *gst_display;
+
+    if (!width && !height) {
+      width = 320;
+      height = 200;
+    }
+
+    if (!m_egl_details) {
+        m_egl_details = new EGLDetails();
+        m_egl_details->display = eglGetCurrentDisplay();
+        m_egl_details->context = eglGetCurrentContext();
+        m_egl_details->draw = eglGetCurrentSurface(0);
+        m_egl_details->read = eglGetCurrentSurface(1);
+        LOG_MEDIA_MESSAGE("display %p context %p", m_egl_details->display, m_egl_details->context);
+    }
+
+    /* reset error state */
+    while (glGetError() != GL_NO_ERROR);
+
+    gst_display = gst_egl_display_new (m_egl_details->display, NULL, NULL);
+    pool = gst_egl_image_memory_pool_new (size, gst_display, this,
+        destroy_pool_resources);
+    gst_egl_display_unref (gst_display);
+
+    for (i = 0; i < size; i++) {
+        GLuint tid;
+        EGLImageKHR image;
+
+        error = GL_NO_ERROR;
+        glGenTextures (1, &tid);
+        if ((error = glGetError ()) != GL_NO_ERROR) {
+            LOG_MEDIA_MESSAGE("glGenTextures failed %x", error);
+            goto failed;
+        }
+
+        glBindTexture (GL_TEXTURE_2D, tid);
+        glTexImage2D (GL_TEXTURE_2D, 0, GL_RGBA, width, height, 0, GL_RGBA,
+            GL_UNSIGNED_BYTE, NULL);
+        if ((error = glGetError ()) != GL_NO_ERROR) {
+          LOG_MEDIA_MESSAGE("glTexImage2D failed %x", error);
+          goto failed;
+        }
+        /* Create EGL Image */
+        error = EGL_SUCCESS;
+        image = eglCreateImageKHR (m_egl_details->display, m_egl_details->context,
+            EGL_GL_TEXTURE_2D_KHR, (EGLClientBuffer) tid, 0);
+
+        if (image == EGL_NO_IMAGE_KHR) {
+          if ((error = eglGetError ()) != EGL_SUCCESS) {
+            LOG_MEDIA_MESSAGE("eglCreateImageKHR failed %x", error);
+          } else {
+            LOG_MEDIA_MESSAGE("eglCreateImageKHR failed");
+          }
+          goto failed;
+        }
+        LOG_MEDIA_MESSAGE("created texture %x image %p", tid, image);
+        gst_egl_image_memory_pool_set_resources (pool, i, (EGLClientBuffer) tid,
+            image);
+    }
+    return pool;
+
+failed:
+    gst_egl_image_memory_pool_unref (pool);
+    return NULL;
+}
+#endif // !GST_API_VERSION_1
+
+#if USE(ACCELERATED_COMPOSITING) && USE(TEXTURE_MAPPER_GL)
+#if USE(COORDINATED_GRAPHICS) && defined(GST_API_VERSION_1)
 PassRefPtr<BitmapTexture> MediaPlayerPrivateGStreamerBase::updateTexture(TextureMapper* textureMapper)
 {
     g_mutex_lock(m_bufferMutex);
@@ -330,7 +707,6 @@
         return 0;
     }
 
-    const void* srcData = 0;
 #ifdef GST_API_VERSION_1
     GRefPtr<GstCaps> caps = currentVideoSinkCaps();
 #else
@@ -366,6 +742,58 @@
     }
 #endif
 
+#if USE(OPENGL_ES_2) && GST_CHECK_VERSION(1, 1, 2)
+    GstMemory *mem;
+    if (gst_buffer_n_memory (m_buffer) >= 1) {
+        if ((mem = gst_buffer_peek_memory (m_buffer, 0)) && gst_is_egl_image_memory (mem)) {
+            guint n, i;
+
+            n = gst_buffer_n_memory (m_buffer);
+
+            LOG_MEDIA_MESSAGE("MediaPlayerPrivateGStreamerBase::updateTexture: buffer contains %d memories", n);
+
+            n = 1; // FIXME
+            const BitmapTextureGL* textureGL = static_cast<const BitmapTextureGL*>(texture.get()); // FIXME
+
+            for (i = 0; i < n; i++) {
+                mem = gst_buffer_peek_memory (m_buffer, i);
+
+                g_assert (gst_is_egl_image_memory (mem));
+
+                if (i == 0)
+                    glActiveTexture (GL_TEXTURE0);
+                else if (i == 1)
+                    glActiveTexture (GL_TEXTURE1);
+                else if (i == 2)
+                    glActiveTexture (GL_TEXTURE2);
+
+                glBindTexture (GL_TEXTURE_2D, textureGL->id()); // FIXME
+                glEGLImageTargetTexture2DOES (GL_TEXTURE_2D,
+                    gst_egl_image_memory_get_image (mem));
+
+                GLuint error = glGetError ();
+                if (error != GL_NO_ERROR)
+                    LOG_ERROR("MediaPlayerPrivateGStreamerBase::updateTexture: glEGLImageTargetTexture2DOES returned 0x%04x\n", error);
+
+                m_orientation = gst_egl_image_memory_get_orientation (mem);
+                if (m_orientation != GST_VIDEO_GL_TEXTURE_ORIENTATION_X_NORMAL_Y_NORMAL
+                    && m_orientation != GST_VIDEO_GL_TEXTURE_ORIENTATION_X_NORMAL_Y_FLIP) {
+                    LOG_ERROR("MediaPlayerPrivateGStreamerBase::updateTexture: invalid GstEGLImage orientation");
+                }
+                else
+                  LOG_MEDIA_MESSAGE("MediaPlayerPrivateGStreamerBase::updateTexture: texture orientation is Y FLIP?: %d",
+                      (m_orientation == GST_VIDEO_GL_TEXTURE_ORIENTATION_X_NORMAL_Y_FLIP));
+            }
+
+            g_mutex_unlock(m_bufferMutex);
+            client()->setPlatformLayerNeedsDisplay();
+            return texture;
+        }
+    }
+
+#else
+
+    const void* srcData = 0;
 #ifdef GST_API_VERSION_1
     GstMapInfo srcInfo;
     gst_buffer_map(m_buffer, &srcInfo, GST_MAP_READ);
@@ -382,6 +810,43 @@
 
     g_mutex_unlock(m_bufferMutex);
     return texture;
+#endif
+    return 0;
+}
+#else
+void MediaPlayerPrivateGStreamerBase::updateTexture()
+{
+#ifndef GST_API_VERSION_1
+    GstEGLImageMemory *mem;
+
+    mem = m_currentEGLMemory;
+
+    if (!mem)
+        return;
+
+    GLint texId = static_cast<const BitmapTextureGL*>(m_texture.get())->id();
+
+    GLint ctexId;
+    glGetIntegerv(GL_TEXTURE_BINDING_2D, &ctexId);
+
+    LOG_MEDIA_MESSAGE ("Upload EGL image: %p on texture %d current texture was: %d",
+        gst_egl_image_memory_get_image (mem), texId, ctexId);
+
+    glEnable(GL_TEXTURE_2D);
+    glBindTexture (GL_TEXTURE_2D, texId);
+    glEGLImageTargetTexture2DOES (GL_TEXTURE_2D, gst_egl_image_memory_get_image (mem));
+    glTexParameterf(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR);
+    glTexParameterf(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR);
+#endif
+}
+#endif
+#endif
+
+#ifndef GST_API_VERSION_1
+void MediaPlayerPrivateGStreamerBase::triggerRepaint()
+{
+    client()->setPlatformLayerNeedsDisplay();
+    m_player->repaint();
 }
 #endif
 
@@ -410,7 +875,7 @@
 
 void MediaPlayerPrivateGStreamerBase::paint(GraphicsContext* context, const IntRect& rect)
 {
-#if USE(ACCELERATED_COMPOSITING) && USE(TEXTURE_MAPPER_GL) && !USE(COORDINATED_GRAPHICS)
+#if USE(ACCELERATED_COMPOSITING) && USE(TEXTURE_MAPPER_GL)
     if (client())
         return;
 #endif
@@ -448,8 +913,8 @@
     g_mutex_unlock(m_bufferMutex);
 }
 
-#if USE(ACCELERATED_COMPOSITING) && USE(TEXTURE_MAPPER_GL) && !USE(COORDINATED_GRAPHICS)
-void MediaPlayerPrivateGStreamerBase::paintToTextureMapper(TextureMapper* textureMapper, const FloatRect& targetRect, const TransformationMatrix& matrix, float opacity)
+#if USE(ACCELERATED_COMPOSITING) && USE(TEXTURE_MAPPER_GL)
+void MediaPlayerPrivateGStreamerBase::paintToTextureMapper(TextureMapper* textureMapper, const FloatRect& targetRect, const TransformationMatrix& modelViewMatrix, float opacity)
 {
     if (textureMapper->accelerationMode() != TextureMapper::OpenGLMode)
         return;
@@ -457,9 +922,56 @@
     if (!m_player->visible())
         return;
 
+#if USE(COORDINATED_GRAPHICS) && defined(GST_API_VERSION_1)
     RefPtr<BitmapTexture> texture = updateTexture(textureMapper);
-    if (texture)
-        textureMapper->drawTexture(*texture.get(), targetRect, matrix, opacity);
+    if (texture) {
+#if USE(OPENGL_ES_2) && GST_CHECK_VERSION(1, 1, 2)
+        if (m_orientation == GST_VIDEO_GL_TEXTURE_ORIENTATION_X_NORMAL_Y_FLIP) {
+            TransformationMatrix matrix(modelViewMatrix);
+            matrix.rotate3d(180, 0, 0);
+            matrix.translateRight(0, targetRect.height());
+            textureMapper->drawTexture(*texture.get(), targetRect, matrix, opacity);
+        }
+        else {
+            textureMapper->drawTexture(*texture.get(), targetRect, modelViewMatrix, opacity);
+        }
+#else
+        textureMapper->drawTexture(*texture.get(), targetRect, modelViewMatrix, opacity);
+#endif
+    }
+#else
+
+#ifndef GST_API_VERSION_1
+    IntSize size = naturalSize();
+
+    if (!m_texture) {
+        m_texture = textureMapper->acquireTextureFromPool(size);
+        if (!m_texture) {
+            LOG_MEDIA_MESSAGE("failed acquiring texture");
+        }
+    }
+
+    dequeueObjects();
+
+    if (m_texture) {
+        g_mutex_lock (m_queueLock);
+        updateTexture();
+        TransformationMatrix mmatrix = modelViewMatrix;
+        mmatrix.setM22(-mmatrix.m22());
+        mmatrix.setM42(targetRect.maxY() + mmatrix.m42());
+        textureMapper->drawTexture(*m_texture.get(), targetRect, mmatrix, opacity);
+        if (m_lastEGLMemory) {
+            gst_egl_image_memory_unref (m_lastEGLMemory);
+            m_lastEGLMemory = NULL;
+        }
+        if (m_currentEGLMemory) {
+            m_lastEGLMemory = m_currentEGLMemory;
+            m_currentEGLMemory = NULL;
+        }
+        g_mutex_unlock (m_queueLock);
+    }
+#endif // GST_API_VERSION_1
+#endif
 }
 #endif
 
@@ -530,11 +1042,23 @@
     m_gstGWorld = GStreamerGWorld::createGWorld(pipeline);
     m_webkitVideoSink = webkitVideoSinkNew(m_gstGWorld.get());
 #else
-    UNUSED_PARAM(pipeline);
+    m_pipeline = pipeline;
+#ifdef GST_API_VERSION_1
     m_webkitVideoSink = webkitVideoSinkNew();
-#endif
-
     m_repaintHandler = g_signal_connect(m_webkitVideoSink.get(), "repaint-requested", G_CALLBACK(mediaPlayerPrivateRepaintCallback), this);
+#else
+    m_webkitVideoSink = gst_element_factory_make("fakesink", "vsink");
+    g_object_set (m_webkitVideoSink.get(), "sync", TRUE, "silent", TRUE,
+        "enable-last-buffer", FALSE,
+        "qos", TRUE,
+        "max-lateness", 20 * GST_MSECOND, "signal-handoffs", TRUE, NULL);
+    g_signal_connect (m_webkitVideoSink.get(), "preroll-handoff", G_CALLBACK (mediaPlayerPrivateVideoPrerollCallback), this);
+    g_signal_connect (m_webkitVideoSink.get(), "handoff", G_CALLBACK (mediaPlayerPrivateVideoBufferCallback), this);
+
+    GRefPtr<GstPad> videoSinkPad = adoptGRef(gst_element_get_static_pad(m_webkitVideoSink.get(), "sink"));
+    gst_pad_add_event_probe(videoSinkPad.get(), G_CALLBACK (mediaPlayerPrivateVideoEventCallback), this);
+#endif
+#endif
 
 #if USE(NATIVE_FULLSCREEN_VIDEO)
     // Build a new video sink consisting of a bin containing a tee
@@ -559,7 +1083,7 @@
 #endif
 
     GstElement* actualVideoSink = 0;
-    m_fpsSink = gst_element_factory_make("fpsdisplaysink", "sink");
+    m_fpsSink = gst_element_factory_make("disabledfpsdisplaysink", "sink");
     if (m_fpsSink) {
         // The verbose property has been added in -bad 0.10.22. Making
         // this whole code depend on it because we don't want
@@ -596,8 +1120,12 @@
         actualVideoSink = m_webkitVideoSink.get();
     }
 
-    ASSERT(actualVideoSink);
+#if USE(OPENGL_ES_2) && GST_CHECK_VERSION(1, 1, 2)
+    else
+        g_object_set(m_fpsSink, "text-overlay", FALSE , NULL);
+#endif
 
+    ASSERT(actualVideoSink);
 #if USE(NATIVE_FULLSCREEN_VIDEO)
     // Faster elements linking.
     gst_element_link_pads_full(queue, "src", actualVideoSink, "sink", GST_PAD_LINK_CHECK_NOTHING);
diff -u qtwebkit-opensource-src-5.2.1/Source/WebCore/platform/graphics/gstreamer/MediaPlayerPrivateGStreamerBase.h qt5webkit-5.2.1/Source/WebCore/platform/graphics/gstreamer/MediaPlayerPrivateGStreamerBase.h
--- qtwebkit-opensource-src-5.2.1/Source/WebCore/platform/graphics/gstreamer/MediaPlayerPrivateGStreamerBase.h	2014-02-01 21:37:48.000000000 +0100
+++ qt5webkit-5.2.1/Source/WebCore/platform/graphics/gstreamer/MediaPlayerPrivateGStreamerBase.h	2014-02-24 10:57:35.000000000 +0100
@@ -31,7 +31,7 @@
 
 #include <wtf/Forward.h>
 
-#if USE(ACCELERATED_COMPOSITING) && USE(TEXTURE_MAPPER_GL) && !USE(COORDINATED_GRAPHICS)
+#if USE(ACCELERATED_COMPOSITING) && USE(TEXTURE_MAPPER_GL)
 #include "TextureMapperPlatformLayer.h"
 #endif
 
@@ -41,6 +41,12 @@
 typedef struct _GstStreamVolume GstStreamVolume;
 typedef struct _WebKitVideoSink WebKitVideoSink;
 
+typedef struct _GstMiniObject GstMiniObject;
+
+typedef struct _GstEGLImageMemoryPool GstEGLImageMemoryPool;
+typedef struct _GstEGLImageMemory GstEGLImageMemory;
+typedef struct _EGLDetails EGLDetails;
+
 namespace WebCore {
 
 class FullscreenVideoControllerGStreamer;
@@ -50,7 +56,7 @@
 class GStreamerGWorld;
 
 class MediaPlayerPrivateGStreamerBase : public MediaPlayerPrivateInterface
-#if USE(ACCELERATED_COMPOSITING) && USE(TEXTURE_MAPPER_GL) && !USE(COORDINATED_GRAPHICS)
+#if USE(ACCELERATED_COMPOSITING) && USE(TEXTURE_MAPPER_GL)
     , public TextureMapperPlatformLayer
 #endif
 {
@@ -103,12 +109,24 @@
     unsigned audioDecodedByteCount() const;
     unsigned videoDecodedByteCount() const;
 
-#if USE(ACCELERATED_COMPOSITING) && USE(TEXTURE_MAPPER_GL) && !USE(COORDINATED_GRAPHICS)
+#if USE(ACCELERATED_COMPOSITING) && USE(TEXTURE_MAPPER_GL)
     virtual PlatformLayer* platformLayer() const { return const_cast<MediaPlayerPrivateGStreamerBase*>(this); }
     virtual bool supportsAcceleratedRendering() const { return true; }
     virtual void paintToTextureMapper(TextureMapper*, const FloatRect&, const TransformationMatrix&, float);
 #endif
 
+#ifndef GST_API_VERSION_1
+    void updateEGLMemory (GstBuffer * buffer);
+    gboolean queueObject(GstMiniObject * obj, gboolean synchronous);
+    void dequeueObjects();
+    void queueFlushStart();
+    void queueFlushStop();
+    void triggerRepaint();
+    void flushLastEGLMemory();
+    GstEGLImageMemoryPool* createEGLPool(gint size, gint width, gint height);
+#endif
+    GstElement* pipeline() const { return m_pipeline; }
+
 protected:
     MediaPlayerPrivateGStreamerBase(MediaPlayer*);
     GstElement* createVideoSink(GstElement* pipeline);
@@ -136,9 +154,26 @@
     unsigned long m_volumeSignalHandler;
     unsigned long m_muteSignalHandler;
     mutable IntSize m_videoSize;
-#if USE(ACCELERATED_COMPOSITING) && USE(TEXTURE_MAPPER_GL) && !USE(COORDINATED_GRAPHICS)
+#if USE(ACCELERATED_COMPOSITING) && USE(TEXTURE_MAPPER_GL)
+#if USE(COORDINATED_GRAPHICS) && defined(GST_API_VERSION_1)
     PassRefPtr<BitmapTexture> updateTexture(TextureMapper*);
+#else
+    void updateTexture();
+    RefPtr<BitmapTexture> m_texture;
+#endif
+    guint m_orientation;
+#endif
+#ifndef GST_API_VERSION_1
+    GAsyncQueue *m_queue;
+    GMutex *m_queueLock;
+    GCond *m_queueCond;
+    bool m_queueFlushing;
+    GstMiniObject *m_queueLastObject;
+    GstEGLImageMemory *m_currentEGLMemory;
+    GstEGLImageMemory *m_lastEGLMemory;
+    EGLDetails *m_egl_details;
 #endif
+    GstElement* m_pipeline;
 };
 }
 
diff -u qtwebkit-opensource-src-5.2.1/Source/WebCore/platform/graphics/gstreamer/MediaPlayerPrivateGStreamer.cpp qt5webkit-5.2.1/Source/WebCore/platform/graphics/gstreamer/MediaPlayerPrivateGStreamer.cpp
--- qtwebkit-opensource-src-5.2.1/Source/WebCore/platform/graphics/gstreamer/MediaPlayerPrivateGStreamer.cpp	2014-02-01 21:37:48.000000000 +0100
+++ qt5webkit-5.2.1/Source/WebCore/platform/graphics/gstreamer/MediaPlayerPrivateGStreamer.cpp	2014-02-24 12:16:22.000000000 +0100
@@ -115,6 +115,19 @@
     return FALSE;
 }
 
+static GstBusSyncReply mediaPlayerPrivateSyncMessageCallback (GstBus * bus, GstMessage * message, MediaPlayerPrivateGStreamer* player)
+{
+#ifndef GST_API_VERSION_1
+  if ((GST_MESSAGE_TYPE (message) == GST_MESSAGE_ELEMENT) &&
+      gst_structure_has_name (message->structure, "need-egl-pool")) {
+    player->queueObject (GST_MINI_OBJECT_CAST (gst_message_ref (message)), TRUE);
+  }
+#else
+  // TODO
+#endif
+  return GST_BUS_PASS;
+}
+
 #ifdef GST_API_VERSION_1
 static void setAudioStreamPropertiesCallback(GstChildProxy*, GObject* object, gchar*,
     MediaPlayerPrivateGStreamer* player)
@@ -128,7 +141,8 @@
 static gboolean mediaPlayerPrivateVideoChangeTimeoutCallback(MediaPlayerPrivateGStreamer* player)
 {
     // This is the callback of the timeout source created in ::videoChanged.
-    player->notifyPlayerOfVideo();
+    if (player)
+        player->notifyPlayerOfVideo();
     return FALSE;
 }
 
@@ -271,9 +285,11 @@
 
     if (m_videoTimerHandler)
         g_source_remove(m_videoTimerHandler);
+    m_videoTimerHandler = 0;
 
     if (m_audioTimerHandler)
         g_source_remove(m_audioTimerHandler);
+    m_audioTimerHandler = 0;
 }
 
 void MediaPlayerPrivateGStreamer::load(const String& url)
@@ -396,6 +412,10 @@
 
 void MediaPlayerPrivateGStreamer::prepareToPlay()
 {
+#ifndef GST_API_VERSION_1
+    dequeueObjects();
+#endif
+
     m_preload = MediaPlayer::Auto;
     if (m_delayingLoad) {
         m_delayingLoad = false;
@@ -421,6 +441,11 @@
     if (currentState < GST_STATE_PAUSED && pendingState <= GST_STATE_PAUSED)
         return;
 
+#ifndef GST_API_VERSION_1
+    // In case we were waiting for providing a pool dequeue.
+    dequeueObjects();
+#endif
+
     if (changePipelineState(GST_STATE_PAUSED))
         INFO_MEDIA_MESSAGE("Pause");
 }
@@ -556,8 +581,6 @@
 
 void MediaPlayerPrivateGStreamer::videoChanged()
 {
-    if (m_videoTimerHandler)
-        g_source_remove(m_videoTimerHandler);
     m_videoTimerHandler = g_timeout_add(0, reinterpret_cast<GSourceFunc>(mediaPlayerPrivateVideoChangeTimeoutCallback), this);
 }
 
@@ -578,8 +601,6 @@
 
 void MediaPlayerPrivateGStreamer::audioChanged()
 {
-    if (m_audioTimerHandler)
-        g_source_remove(m_audioTimerHandler);
     m_audioTimerHandler = g_timeout_add(0, reinterpret_cast<GSourceFunc>(mediaPlayerPrivateAudioChangeTimeoutCallback), this);
 }
 
@@ -1339,8 +1360,15 @@
 
     if (!m_player->mediaPlayerClient()->mediaPlayerIsLooping()) {
         m_paused = true;
+#ifndef GST_API_VERSION_1
+        LOG_MEDIA_MESSAGE("Setting pipeline to NULL state");
+        queueFlushStart();
+#endif
         gst_element_set_state(m_playBin.get(), GST_STATE_NULL);
         m_downloadFinished = false;
+#ifndef GST_API_VERSION_1
+        queueFlushStop();
+#endif
     }
 }
 
@@ -1594,10 +1622,15 @@
     setStreamVolumeElement(GST_STREAM_VOLUME(m_playBin.get()));
 
     GRefPtr<GstBus> bus = webkitGstPipelineGetBus(GST_PIPELINE(m_playBin.get()));
+#ifdef GST_API_VERSION_1
+    gst_bus_set_sync_handler(bus.get(), (GstBusSyncHandler) mediaPlayerPrivateSyncMessageCallback, this, 0);
+#else
+    gst_bus_set_sync_handler(bus.get(), (GstBusSyncHandler) mediaPlayerPrivateSyncMessageCallback, this);
+#endif
     gst_bus_add_signal_watch(bus.get());
     g_signal_connect(bus.get(), "message", G_CALLBACK(mediaPlayerPrivateMessageCallback), this);
 
-    g_object_set(m_playBin.get(), "mute", m_player->muted(), NULL);
+    g_object_set(m_playBin.get(), "mute", m_player->muted(), "flags", GST_PLAY_FLAG_NATIVE_VIDEO | GST_PLAY_FLAG_SOFT_VOLUME | GST_PLAY_FLAG_AUDIO | GST_PLAY_FLAG_VIDEO, NULL);
 
     g_signal_connect(m_playBin.get(), "notify::source", G_CALLBACK(mediaPlayerPrivateSourceChangedCallback), this);
     g_signal_connect(m_playBin.get(), "video-changed", G_CALLBACK(mediaPlayerPrivateVideoChangedCallback), this);
diff -u qtwebkit-opensource-src-5.2.1/Source/WebCore/platform/graphics/gstreamer/VideoSinkGStreamer.cpp qt5webkit-5.2.1/Source/WebCore/platform/graphics/gstreamer/VideoSinkGStreamer.cpp
--- qtwebkit-opensource-src-5.2.1/Source/WebCore/platform/graphics/gstreamer/VideoSinkGStreamer.cpp	2014-02-01 21:37:48.000000000 +0100
+++ qt5webkit-5.2.1/Source/WebCore/platform/graphics/gstreamer/VideoSinkGStreamer.cpp	2014-02-24 10:57:35.000000000 +0100
@@ -40,15 +40,39 @@
 #endif
 #include <wtf/FastAllocBase.h>
 
+#if USE(EGL)
+#include <EGL/egl.h>
+#include <EGL/eglext.h>
+#endif
+
+#if USE(OPENGL_ES_2)
+#include <GLES2/gl2.h>
+#include <GLES2/gl2ext.h>
+#if GST_CHECK_VERSION(1, 1, 2)
+#include <gst/egl/egl.h>
+
+#endif
+#endif
+
 // CAIRO_FORMAT_RGB24 used to render the video buffers is little/big endian dependant.
 #ifdef GST_API_VERSION_1
 #if G_BYTE_ORDER == G_LITTLE_ENDIAN
+#if USE(OPENGL_ES_2) && GST_CHECK_VERSION(1, 1, 2)
+#define GST_CAPS_FORMAT "{ RGBA }"
+#else
 #define GST_CAPS_FORMAT "{ BGRx, BGRA }"
+#endif
 #else
 #define GST_CAPS_FORMAT "{ xRGB, ARGB }"
 #endif
+
 #if GST_CHECK_VERSION(1, 1, 0)
-#define GST_FEATURED_CAPS GST_VIDEO_CAPS_MAKE_WITH_FEATURES(GST_CAPS_FEATURE_META_GST_VIDEO_GL_TEXTURE_UPLOAD_META, GST_CAPS_FORMAT) ";"
+#define GST_FEATURED_CAPS_GL GST_VIDEO_CAPS_MAKE_WITH_FEATURES(GST_CAPS_FEATURE_META_GST_VIDEO_GL_TEXTURE_UPLOAD_META, GST_CAPS_FORMAT) ";"
+#if GST_CHECK_VERSION(1, 1, 2)
+#define GST_FEATURED_CAPS GST_FEATURED_CAPS_GL GST_VIDEO_CAPS_MAKE_WITH_FEATURES(GST_CAPS_FEATURE_MEMORY_EGL_IMAGE, GST_CAPS_FORMAT) ";"
+#else
+#define GST_FEATURED_CAPS GST_FEATURED_CAPS_GL
+#endif
 #else
 #define GST_FEATURED_CAPS
 #endif
@@ -107,6 +131,15 @@
     //
     // Protected by the buffer mutex
     bool unlocked;
+
+#if USE(OPENGL_ES_2) && GST_CHECK_VERSION(1, 1, 2)
+    GstBufferPool *pool;
+    GstBuffer *last_buffer;
+
+    GCond* allocateCondition;
+    GMutex* allocateMutex;
+    GstBuffer* allocateBuffer;
+#endif
 };
 
 #define webkit_video_sink_parent_class parent_class
@@ -129,8 +162,440 @@
 #ifdef GST_API_VERSION_1
     gst_video_info_init(&sink->priv->info);
 #endif
+
+#if USE(OPENGL_ES_2) && GST_CHECK_VERSION(1, 1, 2)
+    sink->priv->pool = NULL;
+    sink->priv->last_buffer = NULL;
+
+    sink->priv->allocateCondition = WTF::fastNew<GCond>();
+    g_cond_init(sink->priv->allocateCondition);
+    sink->priv->allocateMutex = WTF::fastNew<GMutex>();
+    g_mutex_init(sink->priv->allocateMutex);
+    sink->priv->allocateBuffer = NULL;
+#endif
+}
+
+#if USE(OPENGL_ES_2) && GST_CHECK_VERSION(1, 1, 2)
+/* FIXME: start of Copy/Past from eglglessink */
+
+gboolean
+got_gl_error (const char *wtf)
+{
+  GLuint error = GL_NO_ERROR;
+
+  if ((error = glGetError ()) != GL_NO_ERROR) {
+    GST_CAT_ERROR (GST_CAT_DEFAULT, "GL ERROR: %s returned 0x%04x", wtf, error);
+    return TRUE;
+  }
+  return FALSE;
+}
+
+gboolean
+got_egl_error (const char *wtf)
+{
+  EGLint error;
+
+  if ((error = eglGetError ()) != EGL_SUCCESS) {
+    GST_CAT_DEBUG (GST_CAT_DEFAULT, "EGL ERROR: %s returned 0x%04x", wtf,
+        error);
+    return TRUE;
+  }
+
+  return FALSE;
+}
+
+typedef struct
+{
+  GLuint texture;
+} GstEGLGLESImageData;
+
+static void
+gst_egl_gles_image_data_free (GstEGLGLESImageData * data)
+{
+  glDeleteTextures (1, &data->texture);
+  g_slice_free (GstEGLGLESImageData, data);
+}
+
+GstBuffer *
+gst_egl_adaptation_allocate_eglimage (EGLContext eglcontext, GstEGLDisplay *display,
+    GstAllocator * allocator, GstVideoFormat format, gint width, gint height)
+{
+  GstEGLGLESImageData *data = NULL;
+  GstBuffer *buffer;
+  GstVideoInfo info;
+  guint i;
+  gint stride[3];
+  gsize offset[3];
+  GstMemory *mem[3] = { NULL, NULL, NULL };
+  guint n_mem;
+  GstMemoryFlags flags = GST_MEMORY_FLAG_NO_SHARE;
+
+  memset (stride, 0, sizeof (stride));
+  memset (offset, 0, sizeof (offset));
+
+  if (!gst_egl_image_memory_is_mappable ())
+    flags = (GstMemoryFlags) (flags | GST_MEMORY_FLAG_NOT_MAPPABLE);
+
+  gst_video_info_set_format (&info, format, width, height);
+
+  switch (format) {
+  case GST_VIDEO_FORMAT_RGBA:{
+      gsize size;
+      EGLImageKHR image;
+
+      mem[0] =
+          gst_egl_image_allocator_alloc (allocator, display,
+          GST_VIDEO_GL_TEXTURE_TYPE_RGBA, GST_VIDEO_INFO_WIDTH (&info),
+          GST_VIDEO_INFO_HEIGHT (&info), &size);
+      if (mem[0]) {
+        stride[0] = size / GST_VIDEO_INFO_HEIGHT (&info);
+        n_mem = 1;
+        GST_MINI_OBJECT_FLAG_SET (mem[0], GST_MEMORY_FLAG_NO_SHARE);
+      } else {
+        data = g_slice_new0 (GstEGLGLESImageData);
+
+        stride[0] = GST_ROUND_UP_4 (GST_VIDEO_INFO_WIDTH (&info) * 4);
+        size = stride[0] * GST_VIDEO_INFO_HEIGHT (&info);
+
+        glGenTextures (1, &data->texture);
+        if (got_gl_error ("glGenTextures"))
+          goto mem_error;
+
+        glBindTexture (GL_TEXTURE_2D, data->texture);
+        if (got_gl_error ("glBindTexture"))
+          goto mem_error;
+
+        /* Set 2D resizing params */
+        glTexParameteri (GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR);
+        glTexParameteri (GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR);
+
+        /* If these are not set the texture image unit will return
+         * * (R, G, B, A) = black on glTexImage2D for non-POT width/height
+         * * frames. For a deeper explanation take a look at the OpenGL ES
+         * * documentation for glTexParameter */
+        glTexParameteri (GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_CLAMP_TO_EDGE);
+        glTexParameteri (GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_CLAMP_TO_EDGE);
+        if (got_gl_error ("glTexParameteri"))
+          goto mem_error;
+
+        glTexImage2D (GL_TEXTURE_2D, 0, GL_RGBA,
+            GST_VIDEO_INFO_WIDTH (&info),
+            GST_VIDEO_INFO_HEIGHT (&info), 0, GL_RGBA, GL_UNSIGNED_BYTE, NULL);
+        if (got_gl_error ("glTexImage2D"))
+          goto mem_error;
+
+        image =
+            eglCreateImageKHR (gst_egl_display_get (display),
+            eglcontext, EGL_GL_TEXTURE_2D_KHR,
+            (EGLClientBuffer) (guintptr) data->texture, NULL);
+        if (got_egl_error ("eglCreateImageKHR"))
+          goto mem_error;
+
+        mem[0] =
+            gst_egl_image_allocator_wrap (allocator, display,
+            image, GST_VIDEO_GL_TEXTURE_TYPE_RGBA,
+            flags, size, data, (GDestroyNotify) gst_egl_gles_image_data_free);
+
+        n_mem = 1;
+      }
+      break;
+    }
+    default:
+      g_assert_not_reached ();
+      break;
+  }
+
+  buffer = gst_buffer_new ();
+  gst_buffer_add_video_meta_full (buffer, GST_VIDEO_FRAME_FLAG_NONE, format, width, height,
+      GST_VIDEO_INFO_N_PLANES (&info), offset, stride);
+
+  for (i = 0; i < n_mem; i++)
+    gst_buffer_append_memory (buffer, mem[i]);
+
+  return buffer;
+
+mem_error:
+  {
+    if (data)
+      gst_egl_gles_image_data_free (data);
+
+    if (mem[0])
+      gst_memory_unref (mem[0]);
+    if (mem[1])
+      gst_memory_unref (mem[1]);
+    if (mem[2])
+      gst_memory_unref (mem[2]);
+
+    return NULL;
+  }
+}
+
+/* EGLImage memory, buffer pool, etc */
+typedef struct
+{
+    GstVideoBufferPool parent;
+
+    WebKitVideoSink *sink;
+    GstAllocator *allocator;
+    GstAllocationParams params;
+    GstVideoInfo info;
+    gboolean add_metavideo;
+    gboolean want_eglimage;
+    GstEGLDisplay *display;
+  } GstEGLImageBufferPool;
+
+typedef GstVideoBufferPoolClass GstEGLImageBufferPoolClass;
+
+#define GST_EGL_IMAGE_BUFFER_POOL(p) ((GstEGLImageBufferPool*)(p))
+
+GType gst_egl_image_buffer_pool_get_type (void);
+
+G_DEFINE_TYPE (GstEGLImageBufferPool, gst_egl_image_buffer_pool,
+    GST_TYPE_VIDEO_BUFFER_POOL);
+
+/* FIXME: end of Copy/Past from eglglessink */
+
+static gboolean webkitVideoSinkAllocateEGLImage(gpointer data)
+{
+    GstEGLImageBufferPool *pool = reinterpret_cast_ptr<GstEGLImageBufferPool*>(data);
+    WebKitVideoSink* sink = pool->sink;
+    WebKitVideoSinkPrivate* priv = sink->priv;
+
+    g_mutex_lock(priv->allocateMutex);
+
+    priv->allocateBuffer = NULL;
+
+    EGLContext eglcontext = eglGetCurrentContext ();
+    if (eglcontext == EGL_NO_CONTEXT) {
+        /* there is no EGLContext set to current in this thread,
+         * which is required to create an EGLImage
+         */
+        GST_CAT_ERROR (GST_CAT_DEFAULT, "No EGLContext available");
+        g_cond_signal(priv->allocateCondition);
+        g_mutex_unlock(priv->allocateMutex);
+        return FALSE;
+    }
+
+    EGLDisplay egldisplay = eglGetCurrentDisplay ();
+    if (egldisplay == EGL_NO_DISPLAY) {
+        /* there is no EGLDisplay set to current in this thread,
+         * which is required to create an EGLImage
+         */
+        GST_CAT_ERROR (GST_CAT_DEFAULT, "No EGLDisplay available");
+        g_cond_signal(priv->allocateCondition);
+        g_mutex_unlock(priv->allocateMutex);
+        return FALSE;
+    }
+
+    /* no eglTerminate cause we does not own it */
+    GstEGLDisplay *display = gst_egl_display_new (egldisplay, (GDestroyNotify) NULL);
+
+    priv->allocateBuffer = gst_egl_adaptation_allocate_eglimage (eglcontext,
+        display, pool->allocator,
+        pool->info.finfo->format,
+        pool->info.width, pool->info.height);
+
+    if (display)
+      gst_egl_display_unref (display);
+
+    g_cond_signal(priv->allocateCondition);
+    g_mutex_unlock(priv->allocateMutex);
+
+    return FALSE;
+}
+
+/* FIXME: start of Copy/Past from eglglessink */
+
+static const gchar **
+gst_egl_image_buffer_pool_get_options (GstBufferPool * bpool)
+{
+    static const gchar *options[] = { GST_BUFFER_POOL_OPTION_VIDEO_META, NULL
+    };
+
+    return options;
+}
+
+static gboolean
+gst_egl_image_buffer_pool_set_config (GstBufferPool * bpool,
+    GstStructure * config)
+{
+    GstEGLImageBufferPool *pool = GST_EGL_IMAGE_BUFFER_POOL (bpool);
+    GstCaps *caps;
+    GstVideoInfo info;
+
+    if (pool->allocator)
+      gst_object_unref (pool->allocator);
+    pool->allocator = NULL;
+
+    if (!GST_BUFFER_POOL_CLASS
+        (gst_egl_image_buffer_pool_parent_class)->set_config (bpool, config))
+      return FALSE;
+
+    if (!gst_buffer_pool_config_get_params (config, &caps, NULL, NULL, NULL)
+        || !caps)
+      return FALSE;
+
+    if (!gst_video_info_from_caps (&info, caps))
+      return FALSE;
+
+    if (!gst_buffer_pool_config_get_allocator (config, &pool->allocator,
+            &pool->params))
+      return FALSE;
+    if (pool->allocator)
+      gst_object_ref (pool->allocator);
+
+    pool->add_metavideo =
+        gst_buffer_pool_config_has_option (config,
+        GST_BUFFER_POOL_OPTION_VIDEO_META);
+
+    pool->want_eglimage = (pool->allocator
+        && g_strcmp0 (pool->allocator->mem_type, GST_EGL_IMAGE_MEMORY_TYPE) == 0);
+
+    pool->info = info;
+
+    return TRUE;
+}
+
+static GstFlowReturn
+gst_egl_image_buffer_pool_alloc_buffer (GstBufferPool * bpool,
+    GstBuffer ** buffer, GstBufferPoolAcquireParams * params)
+{
+    GstEGLImageBufferPool *pool = GST_EGL_IMAGE_BUFFER_POOL (bpool);
+    WebKitVideoSinkPrivate* priv = pool->sink->priv;
+
+    *buffer = NULL;
+
+    if (!pool->add_metavideo || !pool->want_eglimage)
+      return
+          GST_BUFFER_POOL_CLASS
+          (gst_egl_image_buffer_pool_parent_class)->alloc_buffer (bpool,
+          buffer, params);
+
+    if (!pool->allocator)
+      return GST_FLOW_NOT_NEGOTIATED;
+
+    switch (pool->info.finfo->format) {
+    case GST_VIDEO_FORMAT_RGBA:{
+
+        g_mutex_lock(priv->allocateMutex);
+        g_timeout_add_full(G_PRIORITY_DEFAULT, 0, webkitVideoSinkAllocateEGLImage,
+            gst_object_ref(pool), reinterpret_cast<GDestroyNotify>(gst_object_unref));
+
+        g_cond_wait(priv->allocateCondition, priv->allocateMutex);
+        *buffer = priv->allocateBuffer;
+        g_mutex_unlock(priv->allocateMutex);
+
+        if (!*buffer) {
+          GST_WARNING ("Fallback memory allocation");
+          return
+              GST_BUFFER_POOL_CLASS
+              (gst_egl_image_buffer_pool_parent_class)->alloc_buffer (bpool,
+              buffer, params);
+        }
+
+        return GST_FLOW_OK;
+        break;
+      }
+      default:
+        return
+            GST_BUFFER_POOL_CLASS
+            (gst_egl_image_buffer_pool_parent_class)->alloc_buffer (bpool,
+            buffer, params);
+        break;
+    }
+
+    return GST_FLOW_ERROR;
 }
 
+static GstFlowReturn
+gst_egl_image_buffer_pool_acquire_buffer (GstBufferPool * bpool,
+    GstBuffer ** buffer, GstBufferPoolAcquireParams * params)
+{
+  GstFlowReturn ret;
+  GstEGLImageBufferPool *pool;
+
+  ret =
+      GST_BUFFER_POOL_CLASS
+      (gst_egl_image_buffer_pool_parent_class)->acquire_buffer (bpool,
+      buffer, params);
+  if (ret != GST_FLOW_OK || !*buffer)
+    return ret;
+
+  pool = GST_EGL_IMAGE_BUFFER_POOL (bpool);
+
+  /* XXX: Don't return the memory we just rendered, glEGLImageTargetTexture2DOES()
+   * keeps the EGLImage unmappable until the next one is uploaded
+   */
+  if (*buffer && *buffer == pool->sink->priv->last_buffer) {
+    GstBuffer *oldbuf = *buffer;
+
+    ret =
+        GST_BUFFER_POOL_CLASS
+        (gst_egl_image_buffer_pool_parent_class)->acquire_buffer (bpool,
+        buffer, params);
+    gst_object_replace ((GstObject **) & oldbuf->pool, (GstObject *) pool);
+    gst_buffer_unref (oldbuf);
+  }
+
+  return ret;
+}
+
+static void
+gst_egl_image_buffer_pool_finalize (GObject * object)
+{
+  GstEGLImageBufferPool *pool = reinterpret_cast_ptr<GstEGLImageBufferPool*>(object);
+
+  if (pool->allocator)
+    gst_object_unref (pool->allocator);
+  pool->allocator = NULL;
+
+  if (pool->sink)
+    gst_object_unref (pool->sink);
+  pool->sink = NULL;
+
+  if (pool->display)
+    gst_egl_display_unref (pool->display);
+  pool->display = NULL;
+
+  G_OBJECT_CLASS (gst_egl_image_buffer_pool_parent_class)->finalize (object);
+}
+
+static void
+gst_egl_image_buffer_pool_class_init (GstEGLImageBufferPoolClass * klass)
+{
+  GObjectClass *gobject_class = (GObjectClass *) klass;
+  GstBufferPoolClass *gstbufferpool_class = (GstBufferPoolClass *) klass;
+
+  gobject_class->finalize = gst_egl_image_buffer_pool_finalize;
+  gstbufferpool_class->get_options = gst_egl_image_buffer_pool_get_options;
+  gstbufferpool_class->set_config = gst_egl_image_buffer_pool_set_config;
+  gstbufferpool_class->alloc_buffer = gst_egl_image_buffer_pool_alloc_buffer;
+  gstbufferpool_class->acquire_buffer =
+      gst_egl_image_buffer_pool_acquire_buffer;
+}
+
+static void
+gst_egl_image_buffer_pool_init (GstEGLImageBufferPool * pool)
+{
+}
+
+static GstBufferPool *
+gst_egl_image_buffer_pool_new (WebKitVideoSink *
+    sink, GstEGLDisplay * display)
+{
+  GstEGLImageBufferPool *pool =
+      reinterpret_cast<GstEGLImageBufferPool *>(g_object_new (gst_egl_image_buffer_pool_get_type (), NULL));
+  if (display)
+      pool->display = gst_egl_display_ref (display);
+  pool->sink = reinterpret_cast<WebKitVideoSink*> (gst_object_ref (reinterpret_cast<GstObject*>(sink)));
+
+  return (GstBufferPool *) pool;
+}
+
+/* FIXME: end of Copy/Past from eglglessink */
+
+#endif
+
 static gboolean webkitVideoSinkTimeoutCallback(gpointer data)
 {
     WebKitVideoSink* sink = reinterpret_cast<WebKitVideoSink*>(data);
@@ -148,6 +613,9 @@
     }
 
     g_signal_emit(sink, webkitVideoSinkSignals[REPAINT_REQUESTED], 0, buffer);
+#if USE(OPENGL_ES_2) && GST_CHECK_VERSION(1, 1, 2)
+    gst_buffer_replace (&priv->last_buffer, buffer);
+#endif
     gst_buffer_unref(buffer);
     g_cond_signal(priv->dataCondition);
     g_mutex_unlock(priv->bufferMutex);
@@ -188,7 +656,12 @@
 
     GRefPtr<GstCaps> caps = GST_BUFFER_CAPS(buffer);
 #else
-    GRefPtr<GstCaps> caps = adoptGRef(gst_video_info_to_caps(&priv->info));
+    GRefPtr<GstCaps> caps;
+    // The video info structure is valid only if the sink handled an allocation query.
+    if (GST_VIDEO_INFO_FORMAT(&priv->info) != GST_VIDEO_FORMAT_UNKNOWN)
+        caps = adoptGRef(gst_video_info_to_caps(&priv->info));
+    else
+        caps = priv->currentCaps;
 #endif
 
     GstVideoFormat format;
@@ -207,7 +680,6 @@
         // method scope we can't use gst_buffer_make_writable() here. Also
         // The buffer content should not be changed here because the same buffer
         // could be passed multiple times to this method (in theory).
-
         GstBuffer* newBuffer = createGstBuffer(buffer);
 
         // Check if allocation failed.
@@ -296,6 +768,18 @@
         priv->bufferMutex = 0;
     }
 
+#if USE(OPENGL_ES_2) && GST_CHECK_VERSION(1, 1, 2)
+    if (sink->priv->allocateCondition) {
+        g_cond_clear(priv->allocateCondition);
+        WTF::fastDelete(priv->allocateCondition);
+    }
+
+    if (sink->priv->allocateMutex) {
+        g_mutex_clear(priv->allocateMutex);
+        WTF::fastDelete(priv->allocateMutex);
+    }
+#endif
+
     G_OBJECT_CLASS(parent_class)->dispose(object);
 }
 
@@ -354,7 +838,8 @@
 
 static gboolean webkitVideoSinkStop(GstBaseSink* baseSink)
 {
-    WebKitVideoSinkPrivate* priv = WEBKIT_VIDEO_SINK(baseSink)->priv;
+    WebKitVideoSink* sink = reinterpret_cast_ptr<WebKitVideoSink*>(baseSink);
+    WebKitVideoSinkPrivate* priv = sink->priv;
 
     unlockBufferMutex(priv);
 
@@ -363,6 +848,16 @@
         priv->currentCaps = 0;
     }
 
+#if USE(OPENGL_ES_2) && GST_CHECK_VERSION(1, 1, 2)
+    GST_OBJECT_LOCK (sink);
+    if (priv->last_buffer)
+        gst_buffer_replace (&priv->last_buffer, NULL);
+    if (priv->pool)
+        gst_object_unref (priv->pool);
+    priv->pool = NULL;
+    GST_OBJECT_UNLOCK (sink);
+#endif
+
     return TRUE;
 }
 
@@ -391,6 +886,37 @@
     }
 #endif
 
+#if USE(OPENGL_ES_2) && GST_CHECK_VERSION(1, 1, 2)
+    /* FIXME: start of Copy/Past from eglglessink */
+
+    GstAllocationParams params;
+    gst_allocation_params_init (&params);
+
+    GstBufferPool *newpool =
+      gst_egl_image_buffer_pool_new (sink, NULL);
+    GstStructure *config = gst_buffer_pool_get_config (newpool);
+    /* we need at least 2 buffer because we hold on to the last one */
+    gst_buffer_pool_config_set_params (config, caps, info.size, 2, 0);
+    gst_buffer_pool_config_set_allocator (config, NULL, &params);
+    if (!gst_buffer_pool_set_config (newpool, config)) {
+      gst_object_unref (newpool);
+      GST_ERROR_OBJECT (sink, "Failed to set buffer pool configuration");
+      return FALSE;
+    }
+
+    GST_DEBUG_OBJECT (sink, "Does our pool want GST_EGL_IMAGE_MEMORY_TYPE ? %d", GST_EGL_IMAGE_BUFFER_POOL(newpool)->want_eglimage);
+
+    GST_OBJECT_LOCK (sink);
+    GstBufferPool *oldpool = priv->pool;
+    priv->pool = newpool;
+    GST_OBJECT_UNLOCK (sink);
+
+    if (oldpool)
+      gst_object_unref (oldpool);
+
+    /* End of Copy/Past from eglglessink */
+#endif
+
     gst_caps_replace(&priv->currentCaps, caps);
     return TRUE;
 }
@@ -398,18 +924,111 @@
 #ifdef GST_API_VERSION_1
 static gboolean webkitVideoSinkProposeAllocation(GstBaseSink* baseSink, GstQuery* query)
 {
-    GstCaps* caps;
+    WebKitVideoSink* sink = WEBKIT_VIDEO_SINK(baseSink);
+    GstCaps* caps = NULL;
+
+#if USE(OPENGL_ES_2) && GST_CHECK_VERSION(1, 1, 2)
+    /* FIXME: start of Copy/Past from eglglessink */
+    WebKitVideoSinkPrivate* priv = sink->priv;
+
+    GstAllocationParams params;
+    gst_allocation_params_init (&params);
+
+    gboolean need_pool = TRUE;
+    gst_query_parse_allocation (query, &caps, &need_pool);
+    if (!caps) {
+      GST_ERROR_OBJECT (sink, "allocation query without caps");
+      return FALSE;
+    }
+
+    GstVideoInfo info;
+    if (!gst_video_info_from_caps (&info, caps)) {
+        GST_ERROR_OBJECT (sink, "allocation query with invalid caps");
+        return FALSE;
+    }
+
+    GST_OBJECT_LOCK (sink);
+    GstBufferPool *pool = reinterpret_cast_ptr<GstBufferPool*>(priv->pool ? gst_object_ref (reinterpret_cast_ptr<GstObject*>(priv->pool)) : NULL);
+    GST_OBJECT_UNLOCK (sink);
+
+    GstStructure *config = NULL;
+    guint size;
+    if (pool) {
+        GstCaps *pcaps = NULL;
+
+        /* we had a pool, check caps */
+        GST_DEBUG_OBJECT (sink, "check existing pool caps");
+        config = gst_buffer_pool_get_config (pool);
+        gst_buffer_pool_config_get_params (config, &pcaps, &size, NULL, NULL);
+
+        if (!gst_caps_is_equal (caps, pcaps)) {
+            GST_DEBUG_OBJECT (sink, "pool has different caps");
+            /* different caps, we can't use this pool */
+            gst_object_unref (pool);
+            pool = NULL;
+        }
+        gst_structure_free (config);
+    }
+
+    if (pool == NULL && need_pool) {
+        GstVideoInfo info;
+
+        if (!gst_video_info_from_caps (&info, caps)) {
+            GST_ERROR_OBJECT (sink, "allocation query has invalid caps %"
+                GST_PTR_FORMAT, caps);
+            return FALSE;
+        }
+
+        GST_DEBUG_OBJECT (sink, "create new pool");
+        pool = gst_egl_image_buffer_pool_new (sink, NULL);
+
+        /* the normal size of a frame */
+        size = info.size;
+
+        config = gst_buffer_pool_get_config (pool);
+        /* we need at least 2 buffer because we hold on to the last one */
+        gst_buffer_pool_config_set_params (config, caps, size, 2, 0);
+        gst_buffer_pool_config_set_allocator (config, NULL, &params);
+        if (!gst_buffer_pool_set_config (pool, config)) {
+            gst_object_unref (pool);
+            GST_ERROR_OBJECT (sink, "failed to set pool configuration");
+            return FALSE;
+        }
+    }
+
+    if (pool) {
+        /* we need at least 2 buffer because we hold on to the last one */
+        gst_query_add_allocation_pool (query, pool, size, 2, 0);
+        gst_object_unref (pool);
+    }
+
+    /* First the default allocator */
+    GstAllocator *allocator = NULL;
+    if (!gst_egl_image_memory_is_mappable ()) {
+      allocator = gst_allocator_find (NULL);
+      gst_query_add_allocation_param (query, allocator, &params);
+      gst_object_unref (allocator);
+    }
+
+    allocator = gst_egl_image_allocator_obtain ();
+    if (!gst_egl_image_memory_is_mappable ())
+        params.flags = (GstMemoryFlags) (params.flags | GST_MEMORY_FLAG_NOT_MAPPABLE);
+    gst_query_add_allocation_param (query, allocator, &params);
+    gst_object_unref (allocator);
+
+    /* FIXME: end of Copy/Past from eglglessink */
+#else
     gst_query_parse_allocation(query, &caps, 0);
     if (!caps)
         return FALSE;
 
-    WebKitVideoSink* sink = WEBKIT_VIDEO_SINK(baseSink);
     if (!gst_video_info_from_caps(&sink->priv->info, caps))
         return FALSE;
+#endif
 
     gst_query_add_allocation_meta(query, GST_VIDEO_META_API_TYPE, 0);
     gst_query_add_allocation_meta(query, GST_VIDEO_CROP_META_API_TYPE, 0);
-#if GST_CHECK_VERSION(1, 1, 0)
+#if GST_CHECK_VERSION(1, 1, 0) && !USE(OPENGL_ES_2)
     gst_query_add_allocation_meta(query, GST_VIDEO_GL_TEXTURE_UPLOAD_META_API_TYPE, 0);
 #endif
     return TRUE;
